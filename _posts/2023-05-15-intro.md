# 2023-05-15-intro

Here's the table of contents:

1. TOC
{:toc}

## Proper fit and overfit

In the example below, we need to train the model and make the prediction on the X^2 function. The figure on the left is the proper fit model. The figure on the right is overfit model.
The overfit model has better performance on the training data but poor performance on the testing data.
Click here [links](https://github.com/fastai/fastbook/blob/master/01_intro.ipynb) to see details

<img src="/images/Proper_fit_and_over_fit.jpg" width = "800" height = "380" alt="" align=center />

## Validation Sets and Test Sets

1. The validation sets are to validate the model and improve the model. 

2. Test sets are to evaluate the model and can not be used to improve the model.

Training data is fully exposed, the validation data is less exposed, and test data is hidden.

## Use Judgment in Defining Test Sets

When we choose the validation sets and test sets, these two sets must be representative of the new data we will see in the future.

For example: 
If you are looking at time series data. For a time series, choosing a random subset of the data will be both too easy and not representative of most business use cases.

Suppose we want to split the time series data into training sets and validation sets

<img src="/images/time_series_data.jpg" width = "400" height = "380" alt="" align=center />

The random subset is not good.

<img src="/images/random_subset.jpg" width = "400" height = "380" alt="" align=center />

The earlier data can be training sets, and the later data can be validation sets.

<img src="/images/earlier_data.jpg" width = "400" height = "380" alt="" align=center />
